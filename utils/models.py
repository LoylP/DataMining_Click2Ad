import streamlit as st
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB, MultinomialNB

from sklearn.svm import SVC
from xgboost import XGBClassifier

def select_data_for_prediction():
    if st.session_state.df_normalize is not None:
        data_options = ['df', 'df_smooth', 'df_normalize']
    elif st.session_state.df_smooth is not None:
        data_options = ['df', 'df_smooth']
    elif st.session_state.df is not None:
        data_options = ['df']
    else:
        st.warning("‚ö†Ô∏è Vui l√≤ng t·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc.")
        return None

    df_to_choose = st.selectbox("üîé Ch·ªçn d·ªØ li·ªáu ƒë·ªÉ d·ª± ƒëo√°n:", data_options)
    
    if df_to_choose == 'df_normalize':
        return st.session_state.df_normalize.copy()
    elif df_to_choose == 'df_smooth':
        return st.session_state.df_smooth.copy()
    else:
        return st.session_state.df.copy()

# H√†m ch·ªçn c·ªôt X v√† Y
def select_columns(data):
    columns = list(data.columns)
    X_columns = st.multiselect("Ch·ªçn c·ªôt X (bi·∫øn ƒë·ªôc l·∫≠p):", columns)
    Y_column = st.selectbox("Ch·ªçn c·ªôt Y (bi·∫øn m·ª•c ti√™u):", columns)

    if not X_columns or not Y_column:
        X_columns = columns[:-1]
        Y_column = columns[-1]
    
    X = data[X_columns]
    y = data[Y_column]
    
    return X, y, X_columns, Y_column

def show_algorithm_formula(algorithm):
    if algorithm == "NaiveBayes(Laplace Smoothing)":
        st.markdown("""
        **√Åp d·ª•ng c√¥ng th·ª©c Laplace smoothing:**
        - P(Xk|Ci) = (count(Ci, Xk) + 1) / (count(Ci) + r)
        - Trong ƒë√≥:
          - count(Ci, Xk) l√† s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa ƒë·∫∑c tr∆∞ng Xk trong l·ªõp Ci.
          - count(Ci) l√† t·ªïng s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa t·∫•t c·∫£ c√°c ƒë·∫∑c tr∆∞ng trong l·ªõp Ci.
          - r l√† s·ªë l∆∞·ª£ng c√°c ƒë·∫∑c tr∆∞ng.
        """)
    elif algorithm == "NaiveBayes":
        st.markdown("""
        **√Åp d·ª•ng c√¥ng th·ª©c:**
        - P(Y = y_i | X = x_j) = (P(X = x_j | Y = y_i) * P(Y = y_i)) / P(X = x_j)
        - ƒê√¢y l√† c√¥ng th·ª©c chu·∫©n c·ªßa Naive Bayes, trong ƒë√≥ c√°c ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c gi·∫£ ƒë·ªãnh l√† ƒë·ªôc l·∫≠p v·ªõi nhau.
        """)
    elif algorithm == "DecisionTree(Entropy)":
        st.markdown("""
        **C√¥ng th·ª©c Entropy trong Decision Tree:**
        - Entropy(S) = - ‚àë (p_i * log2(p_i))
        - Trong ƒë√≥:
          - p_i l√† x√°c su·∫•t c·ªßa l·ªõp i trong t·∫≠p S.
        """)
    elif algorithm == "DecisionTree(Gini index)":
        st.markdown("""
        **C√¥ng th·ª©c Gini Index:**
        - Gini(S) = 1 - ‚àë (p_i^2)
        - Trong ƒë√≥:
          - p_i l√† x√°c su·∫•t c·ªßa l·ªõp i trong t·∫≠p S.
        """)
    elif algorithm == "RandomForest":
        st.markdown("""
        **C√¥ng th·ª©c Random Forest:**
        - Random Forest s·ª≠ d·ª•ng nhi·ªÅu c√¢y quy·∫øt ƒë·ªãnh (Decision Trees), m·ªói c√¢y ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi m·ªôt ph·∫ßn m·∫´u ng·∫´u nhi√™n c·ªßa d·ªØ li·ªáu.
        - D·ª± ƒëo√°n ƒë∆∞·ª£c l·∫•y t·ª´ vi·ªác k·∫øt h·ª£p c√°c d·ª± ƒëo√°n c·ªßa c√°c c√¢y.
        """)
    elif algorithm == "KNN":
        st.markdown("""
        **C√¥ng th·ª©c K-Nearest Neighbors (KNN):**
        - D·ª± ƒëo√°n c·ªßa KNN l√† l·ªõp c·ªßa K l√°ng gi·ªÅng g·∫ßn nh·∫•t trong kh√¥ng gian ƒë·∫∑c tr∆∞ng.
        - Class(x) = majority_class(nearest_neighbors(x))
        """)
    elif algorithm == "SVM":
        st.markdown("""
        **C√¥ng th·ª©c Support Vector Machine (SVM):**
        - D·ª± ƒëo√°n c·ªßa SVM l√† h√†m ph√¢n t√°ch t·ªëi ∆∞u nh·∫•t gi·ªØa c√°c l·ªõp trong kh√¥ng gian ƒë·∫∑c tr∆∞ng.
        - C√¥ng th·ª©c: f(x) = w^T x + b
        - M·ª•c ti√™u l√† t·ªëi ƒëa h√≥a kho·∫£ng c√°ch gi·ªØa c√°c ƒëi·ªÉm d·ªØ li·ªáu v√† si√™u ph·∫≥ng ph√¢n c√°ch.
        """)
    elif algorithm == "XGBoost":
        st.markdown("""
        **C√¥ng th·ª©c XGBoost:**
        - XGBoost l√† m√¥ h√¨nh h·ªçc m√°y gradient boosting, n∆°i m·ªói c√¢y quy·∫øt ƒë·ªãnh m·ªõi c·ªë g·∫Øng s·ª≠a ch·ªØa sai s√≥t c·ªßa c√¢y tr∆∞·ªõc ƒë√≥.
        - L·ªõp cu·ªëi c√πng ƒë∆∞·ª£c t√≠nh to√°n b·∫±ng c√°ch c·ªông d·ªìn k·∫øt qu·∫£ c·ªßa c√°c c√¢y quy·∫øt ƒë·ªãnh: y_pred = ‚àë f_t(x)
        """)
    else:
        st.warning("C√¥ng th·ª©c kh√¥ng c√≥ s·∫µn cho thu·∫≠t to√°n n√†y.")
        
# H√†m hu·∫•n luy·ªán m√¥ h√¨nh
def train_model(algorithm, X_train, y_train):
    if algorithm == "DecisionTree(Entropy)":
        model = DecisionTreeClassifier(criterion="entropy")
    elif algorithm == "DecisionTree(Gini index)":
        model = DecisionTreeClassifier(criterion="gini")
    elif algorithm == "RandomForest":
        model = RandomForestClassifier(n_estimators=100, random_state=42)
    elif algorithm == "NaiveBayes":
        model = GaussianNB()
    elif algorithm == "NaiveBayes(Laplace Smoothing)":
        model = MultinomialNB(alpha=1.0)  # Laplace Smoothing
    elif algorithm == "KNN":
        model = KNeighborsClassifier()
    elif algorithm == "SVM":
        model = SVC(probability=True)
    elif algorithm == "XGBoost":
        model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
    else:
        st.error("‚ö†Ô∏è Thu·∫≠t to√°n kh√¥ng h·ª£p l·ªá!")
        return None
    
    model.fit(X_train, y_train)
    return model

# H√†m hi·ªÉn th·ªã v√† nh·∫≠n ƒë·∫ßu v√†o ng∆∞·ªùi d√πng ƒë·ªÉ d·ª± ƒëo√°n
def get_user_input(X_columns, data):
    input_data = {}
    for col in X_columns:
        dtype = data[col].dtype
        if np.issubdtype(dtype, np.number):
            input_data[col] = st.number_input(f"Nh·∫≠p gi√° tr·ªã cho {col}:", value=float(data[col].mean()))
        else:
            input_data[col] = st.text_input(f"Nh·∫≠p gi√° tr·ªã cho {col}:")
    
    return pd.DataFrame([input_data])

# H√†m hi·ªÉn th·ªã k·∫øt qu·∫£ d·ª± ƒëo√°n
def show_prediction_result(input_df):
    if "trained_model" in st.session_state:
        model = st.session_state.trained_model
        prediction = model.predict(input_df)
        st.success(f"üîÆ K·∫øt qu·∫£ d·ª± ƒëo√°n: {prediction[0]}")
    else:
        st.info("üîß Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc khi d·ª± ƒëo√°n.")