import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import random
from utils.preprocessing import handle_categorical_conversion, handle_missing_values, detect_outliers
from utils.apriori import get_numerical_columns, display_column_statistics, parse_bin_ranges, apriori
from utils.smoothing import smoothing
from utils.clustering import get_numerical_columns, plot_clusters_with_labels, kmeans_with_progress
from utils.EDA import show_Histogram, show_Boxplot, show_Scatter, show_Heatmap
from utils.models import select_data_for_prediction, select_columns, train_model, get_user_input, show_prediction_result, show_algorithm_formula
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn import tree

def main():
    # TiÃªu Ä‘á» chÃ­nh
    st.title("ğŸ“Š Demo App Data-Mining")
    st.sidebar.title("ğŸ“Š Menu")
    
    # Khá»Ÿi táº¡o session_state Ä‘á»ƒ lÆ°u dá»¯ liá»‡u
    if "df_raw" not in st.session_state:
        st.session_state.df_raw = None
    if "df" not in st.session_state:
        st.session_state.df = None
    if "df_preprocessing" not in st.session_state:
        st.session_state.df_preprocessing = None
    if "df_smooth" not in st.session_state:
        st.session_state.df_smooth = None
    if "df_normalize" not in st.session_state:
        st.session_state.df_normalize = None

    uploaded_file = st.sidebar.file_uploader("Táº£i lÃªn tá»‡p CSV:", type=["csv"])
    if uploaded_file:
        st.session_state.df_raw = pd.read_csv(uploaded_file)
        st.session_state.df_preprocessing = st.session_state.df_raw.copy()

    # Táº¡o menu tÃ¹y chá»n vá»›i cÃ¡c nÃºt báº¥m
    page = st.sidebar.radio(
        "Chá»n má»™t chá»©c nÄƒng:",
        ["ğŸ  Trang chá»§", "ğŸ›  Xá»­ lÃ½ dá»¯ liá»‡u", "ğŸš« XÃ¡c Ä‘á»‹nh Outliers", "ğŸ”— Äá»™ TÆ°Æ¡ng Quan", "ğŸŒ« Binning/Smoothing", "ğŸš€ Gom Cá»¥m","ğŸŒ³ PhÃ¢n lá»›p", "ğŸ“ˆ EDA", "ğŸ” Prediction"],
        label_visibility="visible"
    )

    if page == "ğŸ  Trang chá»§":
        show_home_page()
    elif page == "ğŸ›  Xá»­ lÃ½ dá»¯ liá»‡u":
        show_data_processing_page()
    elif page == "ğŸš« XÃ¡c Ä‘á»‹nh Outliers":
        show_outlier_detection_page()
    elif page == "ğŸ”— Äá»™ TÆ°Æ¡ng Quan":
        show_correlation_page()
    elif page == "ğŸŒ« Binning/Smoothing":
        show_binning_page()
    elif page == "ğŸš€ Gom Cá»¥m":
        show_clustering_page()
    elif page == "ğŸŒ³ PhÃ¢n lá»›p":
        show_classification_page()
    elif page == "ğŸ“ˆ EDA":
        show_EDA_page()
    elif page == "ğŸ” Prediction":
        show_prediction_page()
    

# Trang chá»§
def show_home_page():
    st.header("ğŸ  Dá»¯ liá»‡u ban Ä‘áº§u")
    
    if st.session_state.df_raw is not None:
        st.write("Dá»¯ liá»‡u hiá»‡n táº¡i Ä‘Æ°á»£c táº£i tá»« file:")
        st.dataframe(st.session_state.df_raw, use_container_width=True)
        
        # Kiá»ƒm tra giÃ¡ trá»‹ null
        st.subheader("âš ï¸ Kiá»ƒm tra giÃ¡ trá»‹ null:")
        show_null_summary()
    else:
        st.warning("Vui lÃ²ng táº£i dá»¯ liá»‡u Ä‘á»ƒ báº¯t Ä‘áº§u.")

def show_null_summary():
    null_values = st.session_state.df_raw.isnull().sum()
    data_types = st.session_state.df_raw.dtypes
    unique_values = st.session_state.df_raw.nunique()
    summary_df = pd.DataFrame({
        "Feature": st.session_state.df_raw.columns,
        "null_values": null_values,
        "data_types": data_types,
        "unique_values": unique_values
    }).reset_index(drop=True)
    
    # Hiá»ƒn thá»‹ báº£ng káº¿t quáº£
    st.dataframe(summary_df, use_container_width=True)

def show_data_processing_page():
    st.header("ğŸ“ˆ Xá»­ lÃ½ dá»¯ liá»‡u")
    
    if st.session_state.df_preprocessing is not None:
        # PhÃ¢n loáº¡i dá»¯ liá»‡u
        categorical_features = st.session_state.df_preprocessing.select_dtypes(include=['object']).columns.tolist()
        numerical_features = st.session_state.df_preprocessing.select_dtypes(include=['number']).columns.tolist()
        
        st.subheader("ğŸ” PhÃ¢n loáº¡i dá»¯ liá»‡u")
        st.write("CÃ¡c cá»™t **Categorical**: ")
        st.write(categorical_features)
        st.write("CÃ¡c cá»™t **Numerical**: ")
        st.write(numerical_features)
        
        # Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u categorical sang dá»¯ liá»‡u sá»‘
        if categorical_features:
            st.subheader("ğŸ”„ Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u Categorical sang sá»‘")
            handle_categorical_conversion(categorical_features)
        
        st.subheader("ğŸ› ï¸ Xá»­ lÃ½ giÃ¡ trá»‹ null")
        handle_missing_values()

        save_button = st.button("ğŸ’¾ LÆ°u dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½")
        if save_button:
            st.session_state.df = st.session_state.df_preprocessing.copy()
            st.success("Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o df!")

    else:
        st.warning("Vui lÃ²ng táº£i dá»¯ liá»‡u Ä‘á»ƒ báº¯t Ä‘áº§u.")

def show_outlier_detection_page():
    st.header("ğŸš« XÃ¡c Ä‘á»‹nh Outliers báº±ng KNN")
    
    if st.session_state.df is not None:
        data_new = st.session_state.df.copy()

        data_with_outliers, outliers, mean_distances, threshold = detect_outliers(data_new)

        st.subheader("ğŸ“ˆ CÃ¡c pháº§n tá»­ Outliers:")
        st.dataframe(outliers, use_container_width=True)

        plt.figure(figsize=(10, 6))
        plt.hist(mean_distances, bins=30, alpha=0.7, label='Distances')
        plt.axvline(threshold, color='r', linestyle='--', label='Threshold')
        plt.legend()
        plt.title('PhÃ¢n phá»‘i khoáº£ng cÃ¡ch trung bÃ¬nh')
        plt.xlabel('Mean Distance')
        plt.ylabel('Frequency')
        st.pyplot(plt.gcf())

        remove_outliers = st.checkbox("Loáº¡i bá» Outliers khá»i dá»¯ liá»‡u")
        
        if remove_outliers:
            data_cleaned = data_with_outliers[data_with_outliers['Outlier'] == False].drop(columns=['Outlier'])
            st.subheader("ğŸ“Š Dá»¯ liá»‡u sau khi loáº¡i bá» Outliers:")
            st.dataframe(data_cleaned, use_container_width=True)
            
            save_button = st.button("ğŸ’¾ LÆ°u dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½")
            if save_button:
                st.session_state.df = data_cleaned
                st.success("Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o df!")

        else:
            st.info("Dá»¯ liá»‡u hiá»‡n táº¡i váº«n giá»¯ láº¡i cÃ¡c outliers.")
    else:
        st.warning("Vui lÃ²ng táº£i vÃ  xá»­ lÃ½ dá»¯ liá»‡u trÆ°á»›c.")

def show_correlation_page():
    st.header("ğŸ”— Äá»™ tÆ°Æ¡ng quan giá»¯a cÃ¡c cá»™t")
    
    if st.session_state.df is not None:
        corr_matrix = st.session_state.df.corr()
        
        f, ax = plt.subplots(figsize=(11, 11))
        sns.heatmap(corr_matrix, annot=True, linewidths=.5, fmt='.1f', ax=ax)
        st.pyplot(f)

        threshold = st.slider("Chá»n má»©c tÆ°Æ¡ng quan tá»‘i thiá»ƒu:", 0.0, 1.0, 0.5, 0.05)
        st.write(f"Má»©c Ä‘á»™ tÆ°Æ¡ng quan tá»‘i thiá»ƒu: {threshold}")
        
        high_corr_pairs = []
        for col1 in corr_matrix.columns:
            for col2 in corr_matrix.columns:
                if col1 != col2 and corr_matrix.loc[col1, col2] > threshold:
                    high_corr_pairs.append((col1, col2, corr_matrix.loc[col1, col2]))
        
        if high_corr_pairs:
            st.subheader("CÃ¡c cáº·p cá»™t cÃ³ Ä‘á»™ tÆ°Æ¡ng quan lá»›n hÆ¡n má»©c Ä‘Ã£ chá»n:")
            for pair in high_corr_pairs:
                st.write(f"{pair[0]} vÃ  {pair[1]}: {pair[2]:.2f}")
        else:
            st.info("KhÃ´ng cÃ³ cáº·p cá»™t nÃ o cÃ³ Ä‘á»™ tÆ°Æ¡ng quan lá»›n hÆ¡n má»©c Ä‘Ã£ chá»n.")
        
        columns_to_remove = st.multiselect("Chá»n cÃ¡c cá»™t Ä‘á»ƒ loáº¡i bá»:", st.session_state.df.columns.tolist())
        
        if columns_to_remove:
            st.subheader("Dá»¯ liá»‡u sau khi loáº¡i bá» cÃ¡c cá»™t Ä‘Ã£ chá»n:")
            data_cleaned = st.session_state.df.drop(columns=columns_to_remove)
            st.dataframe(data_cleaned)
            
            save_button = st.button("ğŸ’¾ LÆ°u dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½")
            if save_button:
                st.session_state.df = data_cleaned
                st.success("Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o df!")
        else:
            st.info("KhÃ´ng cÃ³ cá»™t nÃ o Ä‘Æ°á»£c chá»n Ä‘á»ƒ loáº¡i bá».")
    else:
        st.warning("Vui lÃ²ng táº£i vÃ  xá»­ lÃ½ dá»¯ liá»‡u trÆ°á»›c.")

def show_binning_page():
    st.header("ğŸŒ« Binning - Chia dá»¯ liá»‡u thÃ nh cÃ¡c nhÃ³m")

    if st.session_state.df is not None:
        # Chá»n cá»™t Ä‘á»ƒ thá»±c hiá»‡n binning
        numerical_columns = get_numerical_columns(st.session_state.df)
        df_temp = st.session_state.df.copy()
        
        if numerical_columns:
            column_to_bin = st.selectbox("Chá»n cá»™t sá»‘ há»c Ä‘á»ƒ thá»±c hiá»‡n Binning:", numerical_columns)
            display_column_statistics(df_temp, column_to_bin)
            # Nháº­p khoáº£ng bin
            bin_ranges_input = st.text_input("Nháº­p cÃ¡c khoáº£ng bin (vÃ­ dá»¥: [10, 20, 30, 40]):", "[10, 20, 30, 40]")
            
            if bin_ranges_input:
                bin_ranges = parse_bin_ranges(bin_ranges_input)
                bin_labels = [f"({bin_ranges[i]}-{bin_ranges[i+1]})" for i in range(len(bin_ranges) - 1)]
                
                if len(bin_ranges) - 1 == len(bin_labels):
                    # Thá»±c hiá»‡n binning
                    df_temp['Binned'] = pd.cut(df_temp[column_to_bin], bins=bin_ranges, labels=bin_labels, include_lowest=True)
                    st.write("Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c phÃ¢n nhÃ³m:")
                    st.dataframe(df_temp, use_container_width=True)
                    df_smooth = df_temp

                    df_one_hot = pd.get_dummies(df_temp['Binned'], prefix=column_to_bin)
                    for col in df_one_hot.columns:
                        df_one_hot[col] = df_one_hot[col].astype(int)
                    df_temp = pd.concat([df_temp, df_one_hot], axis=1)
                    df_temp = df_temp.loc[:, df_temp.nunique() == 2]
                    st.write("Dá»¯ liá»‡u binning:")
                    st.dataframe(df_temp, use_container_width=True)

                    # ThÃªm pháº§n xá»­ lÃ½ Apriori
                    st.subheader("ğŸ“‹ TÃ¬m táº­p phá»• biáº¿n vÃ  luáº­t káº¿t há»£p")
                    
                    # Chá»n min_support vÃ  min_confidence
                    min_support = st.slider("Chá»n ngÆ°á»¡ng min_support:", 0.0, 1.0, 0.3, 0.05)
                    min_confidence = st.slider("Chá»n ngÆ°á»¡ng min_confidence:", 0.0, 1.0, 0.5, 0.05)
                    
                    apriori(df_temp, min_support, min_confidence)

                    st.header("ğŸŒ« Smoothing - LÃ m trÆ¡n dá»¯ liá»‡u trong nhÃ³m")
                    if st.button("Smoothing"):
                        # LÃ m trÆ¡n dá»¯ liá»‡u
                        smoothing(df_smooth, column_to_bin)
                        st.session_state.df_smooth = df_smooth
                    
                    st.header("Min Max Normalize")
                    if st.button("Normalize"):
                        data = st.session_state.df_smooth.copy()
                        data = data.drop(data.columns[-1], axis=1)
                        df_normalized = data.copy()
                        columns_to_normalize = data.columns
                        df_normalized[columns_to_normalize] = (data[columns_to_normalize] - data[columns_to_normalize].min()) / \
                                        (data[columns_to_normalize].max() - data[columns_to_normalize].min())

                        st.session_state.df_normalize = df_normalized
                        st.dataframe(st.session_state.df_normalize, use_container_width=True)

                else:
                    st.error("ÄÃ£ xáº£y ra lá»—i khi táº¡o nhÃ£n tá»« cÃ¡c khoáº£ng bin.")
        else:
            st.warning("KhÃ´ng cÃ³ cá»™t sá»‘ há»c trong dá»¯ liá»‡u Ä‘á»ƒ thá»±c hiá»‡n binning.")
    
    else:
        st.warning("Vui lÃ²ng táº£i vÃ  xá»­ lÃ½ dá»¯ liá»‡u trÆ°á»›c.")

def show_clustering_page():
    st.header("ğŸš€ Gom Cá»¥m vá»›i Thuáº­t ToÃ¡n K-Means")
    
    # Kiá»ƒm tra dá»¯ liá»‡u
    if st.session_state.df_normalize is not None:
        data_options = ['df', 'df_smooth', 'df_normalize']
    elif st.session_state.df_smooth is not None:
        data_options = ['df', 'df_smooth']
    elif st.session_state.df is not None:
        data_options = ['df']
    else:
        st.warning("âš ï¸ Vui lÃ²ng táº£i vÃ  xá»­ lÃ½ dá»¯ liá»‡u trÆ°á»›c.")
        return

    col1, col2 = st.columns([2, 1])
    
    with col1:
        # Chá»n dá»¯ liá»‡u
        df_to_choose = st.selectbox("ğŸ“Š Chá»n dá»¯ liá»‡u Ä‘á»ƒ gom cá»¥m:", data_options)
        
        if df_to_choose == 'df_normalize':
            data = st.session_state.df_normalize.copy()
        elif df_to_choose == 'df_smooth':
            data = st.session_state.df_smooth.copy()
        else:
            data = st.session_state.df.copy()
            
        numerical_columns = get_numerical_columns(data)
        selected_columns = st.multiselect(
            "ğŸ“ˆ Chá»n cÃ¡c cá»™t Ä‘á»ƒ gom cá»¥m (2-3 cá»™t):",
            numerical_columns,
            max_selections=3
        )
    
    with col2:
        k = st.slider("ğŸ¯ Sá»‘ lÆ°á»£ng cá»¥m (k):", 2, 6, 3)
        start_clustering = st.button("â–¶ï¸ Báº¯t Ä‘áº§u gom cá»¥m", type="primary")

    if start_clustering and len(selected_columns) >= 2:
        with st.spinner('Äang thá»±c hiá»‡n gom cá»¥m...'):
            # Chuáº©n bá»‹ dá»¯ liá»‡u
            X = data[selected_columns].values
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            # Khá»Ÿi táº¡o centroid
            centroids = X_scaled[random.sample(range(len(X_scaled)), k)]
            
            # Hiá»ƒn thá»‹ centroid ban Ä‘áº§u
            with st.expander("ğŸ’« Centroid ban Ä‘áº§u", expanded=True):
                for i, centroid in enumerate(centroids):
                    st.text(f"Centroid {i + 1}: {centroid}")
            
            # Thá»±c hiá»‡n gom cá»¥m
            progress_bar = st.progress(0)
            status_text = st.empty()
            # Thuáº­t toÃ¡n
            clusters, final_centroids = kmeans_with_progress(X_scaled, k, centroids, progress_bar, status_text)
            status_text.text("âœ… HoÃ n thÃ nh gom cá»¥m!")
            progress_bar.progress(1.0)
            
            # Váº½ Ä‘á»“ thá»‹ náº¿u chá»n 2 cá»™t
            if len(selected_columns) == 2:
                st.subheader("ğŸ“Š Biá»ƒu Ä‘á»“ phÃ¢n cá»¥m")
                plot_clusters_with_labels(X_scaled, clusters, final_centroids)
                st.pyplot(plt.gcf())
            else:
                st.info("â„¹ï¸ Biá»ƒu Ä‘á»“ chá»‰ Ä‘Æ°á»£c hiá»ƒn thá»‹ khi chá»n 2 cá»™t dá»¯ liá»‡u")
            
            # Hiá»ƒn thá»‹ káº¿t quáº£
            result_df = data.copy()
            cluster_labels = np.zeros(len(X))
            for i, cluster in enumerate(clusters):
                for point in cluster:
                    idx = np.where((X_scaled == point).all(axis=1))[0][0]
                    cluster_labels[idx] = i
            
            result_df['Cluster'] = cluster_labels.astype(int)
            st.subheader("ğŸ“‘ Káº¿t quáº£ phÃ¢n cá»¥m")
            st.dataframe(result_df, use_container_width=True)
            
    elif start_clustering:
        st.warning("âš ï¸ Vui lÃ²ng chá»n Ã­t nháº¥t 2 cá»™t Ä‘á»ƒ thá»±c hiá»‡n gom cá»¥m!")

def show_classification_page():
    st.header("ğŸŒ³ PhÃ¢n lá»›p cÃ¢y quyáº¿t Ä‘á»‹nh (Decision Tree)")
    
    # Kiá»ƒm tra dá»¯ liá»‡u
    if st.session_state.df_normalize is not None:
        data_options = ['df', 'df_smooth', 'df_normalize']
    elif st.session_state.df_smooth is not None:
        data_options = ['df', 'df_smooth']
    elif st.session_state.df is not None:
        data_options = ['df']
    else:
        st.warning("âš ï¸ Vui lÃ²ng táº£i vÃ  xá»­ lÃ½ dá»¯ liá»‡u trÆ°á»›c.")
        return

    col1, col2 = st.columns([2, 1])
    
    with col1:
        # Chá»n dá»¯ liá»‡u
        df_to_choose = st.selectbox("ğŸ“Š Chá»n dá»¯ liá»‡u Ä‘á»ƒ phÃ¢n lá»›p:", data_options)
        
        if df_to_choose == 'df_normalize':
            data = st.session_state.df_normalize.copy()
        elif df_to_choose == 'df_smooth':
            data = st.session_state.df_smooth.copy()
        else:
            data = st.session_state.df.copy()

        numerical_columns = get_numerical_columns(data)
        selected_columns = st.multiselect(
            "ğŸ“ˆ Chá»n cÃ¡c thuá»™c tÃ­nh Ä‘á»ƒ phÃ¢n lá»›p:",
            numerical_columns,
        )
        
        with col2:
            chart_type = st.selectbox("ğŸ› ï¸ Chá»n kiá»ƒu tÃ­nh information gain:", ["Entropy", "Gini index"])

            target_column = st.selectbox("ğŸ¯ Chá»n cá»™t má»¥c tiÃªu (target):", data.columns)
            feature_columns = selected_columns

    X = data[selected_columns]
    y = data[target_column]

    # Táº¡o vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh
    if st.button("ğŸ” PhÃ¢n lá»›p vá»›i Decision Tree"):
        criterion = "entropy" if chart_type == "Entropy" else "gini"
        model = DecisionTreeClassifier(criterion=criterion, random_state=42)
        model.fit(X, y)
        
        # Hiá»ƒn thá»‹ káº¿t quáº£
        st.subheader("ğŸŒŸ Káº¿t quáº£ phÃ¢n lá»›p:")
        
        # Váº½ cÃ¢y quyáº¿t Ä‘á»‹nh vá»›i Matplotlib
        fig, ax = plt.subplots(figsize=(12, 6))
        plot_tree(model, feature_names=feature_columns, class_names=[str(c) for c in y.unique()],
                    filled=True, rounded=True, ax=ax)
        st.pyplot(fig)

        st.write(f"**NÃºt gá»‘c cá»§a cÃ¢y quyáº¿t Ä‘á»‹nh:** {model.tree_.value[0]}")
        st.write(f"**Äá»™ sÃ¢u cá»§a cÃ¢y quyáº¿t Ä‘á»‹nh:** {model.get_depth()}")
        st.write(f"**Sá»‘ node cá»§a cÃ¢y:** {model.get_n_leaves()}")


def show_EDA_page():
    st.header("ğŸ“ˆ Exploratory Data Analysis (EDA)")

    # Kiá»ƒm tra dá»¯ liá»‡u
    if st.session_state.df_normalize is not None:
        data_options = ['df', 'df_smooth', 'df_normalize']
    elif st.session_state.df_smooth is not None:
        data_options = ['df', 'df_smooth']
    elif st.session_state.df is not None:
        data_options = ['df']
    else:
        st.warning("âš ï¸ Vui lÃ²ng táº£i vÃ  xá»­ lÃ½ dá»¯ liá»‡u trÆ°á»›c.")
        return

    df_to_choose = st.selectbox("ğŸ“Š Chá»n dá»¯ liá»‡u Ä‘á»ƒ phÃ¢n tÃ­ch:", data_options)

    if df_to_choose == 'df_normalize':
        data = st.session_state.df_normalize.copy()
    elif df_to_choose == 'df_smooth':
        data = st.session_state.df_smooth.copy()
    else:
        data = st.session_state.df.copy()

    # Hiá»ƒn thá»‹ dataframe
    st.subheader("ğŸ“‹ Dá»¯ liá»‡u Ä‘Ã£ chá»n")
    st.dataframe(data, use_container_width=True)
    numerical_columns = data.select_dtypes(include=['number']).columns.tolist()

    if not numerical_columns:
        st.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y cá»™t sá»‘ Ä‘á»ƒ phÃ¢n tÃ­ch.")
        return

    st.subheader("âš™ï¸ Lá»±a chá»n phÃ¢n tÃ­ch")
    chart_type = st.selectbox(
        "ğŸ› ï¸ Chá»n loáº¡i biá»ƒu Ä‘á»“ phÃ¢n tÃ­ch:",
        ["Histogram", "Boxplot", "Scatter Plot", "Heatmap"]
    )

    if chart_type == "Histogram":
        show_Histogram(data, numerical_columns)
    
    elif chart_type == "Boxplot":
        show_Boxplot(data, numerical_columns)

    elif chart_type == "Scatter Plot":
        show_Scatter(data, numerical_columns)

    elif chart_type == "Heatmap":
        show_Heatmap(data, numerical_columns)

def show_prediction_page():

    st.header("ğŸ” Prediction")
    data = select_data_for_prediction()
    if data is None:
        return

    st.subheader("ğŸ“‹ Dá»¯ liá»‡u Ä‘Ã£ chá»n")
    st.dataframe(data, use_container_width=True)

    X, y, X_columns, Y_column = select_columns(data)

    if X is None or y is None:
        st.warning("âš ï¸ Vui lÃ²ng chá»n Ä‘áº§y Ä‘á»§ cá»™t X vÃ  cá»™t Y Ä‘á»ƒ tiáº¿p tá»¥c.")
        return  

    st.write(f"ğŸ¯ Cá»™t X Ä‘Ã£ chá»n: {X_columns}")
    st.write(f"ğŸ¯ Cá»™t Y Ä‘Ã£ chá»n: {y.name}")

    selected_algorithm = st.selectbox(
        "ğŸ“š Chá»n thuáº­t toÃ¡n dá»± Ä‘oÃ¡n", 
        ["DecisionTree(Entropy)", "DecisionTree(Gini index)", "RandomForest", 
         "NaiveBayes", "NaiveBayes(Laplace Smoothing)", "KNN", "SVM", "XGBoost"]
    )
    test_size = st.slider("Tá»· lá»‡ dá»¯ liá»‡u kiá»ƒm tra:", 0.1, 0.5, 0.2)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

    if st.button("ğŸ” Huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh"):
        show_algorithm_formula(selected_algorithm)
        model = train_model(selected_algorithm, X_train, y_train)
        if model:
            # ÄÃ¡nh giÃ¡
            y_pred = model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            st.success(f"ğŸ¯ Äá»™ chÃ­nh xÃ¡c trÃªn táº­p kiá»ƒm tra: {accuracy:.2%}")

            # Hiá»ƒn thá»‹ Confusion Matrix
            st.subheader("ğŸ“Š Confusion Matrix")
            cm = confusion_matrix(y_test, y_pred)
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)
            ax.set_xlabel('Dá»± Ä‘oÃ¡n')
            ax.set_ylabel('Thá»±c táº¿')
            st.pyplot(fig)

            # Hiá»ƒn thá»‹ Classification Report vá»›i Ä‘á»‹nh dáº¡ng Ä‘áº¹p
            st.subheader("ğŸ“ˆ Classification Report")
            report = classification_report(y_test, y_pred, target_names=[str(c) for c in model.classes_], output_dict=True)
            report_df = pd.DataFrame(report).transpose()
            # Äá»‹nh dáº¡ng báº£ng Ä‘áº¹p
            st.write("**Precision, Recall, F1-Score vÃ  Support**")
            st.dataframe(report_df.style.format({
                'precision': '{:.2f}', 
                'recall': '{:.2f}', 
                'f1-score': '{:.2f}', 
                'support': '{:.0f}'
            }).background_gradient(axis=None, cmap='Blues'))

            st.session_state.trained_model = model

    # Form nháº­p liá»‡u Ä‘á»ƒ dá»± Ä‘oÃ¡n
    st.subheader("ğŸ“‹ Form nháº­p liá»‡u dá»± Ä‘oÃ¡n")
    input_df = get_user_input(X_columns, data)

    if st.button("ğŸ“Š Dá»± Ä‘oÃ¡n"):
        show_prediction_result(input_df)

if __name__ == "__main__":
    main()
